# Plan de Pruebas de Software
## Sistema de Chatbot Acad√©mico DCCO/ESPE

---

| **Informaci√≥n del Documento** |  |
|---|---|
| **T√≠tulo** | Plan de Pruebas - Sistema de Chatbot Acad√©mico DCCO/ESPE |
| **Versi√≥n** | 1.0 |
| **Fecha** | 12 de agosto de 2025 |
| **Autor** | Equipo de Desarrollo DCCO |
| **Revisor** | [Pendiente] |
| **Aprobador** | [Pendiente] |
| **Estado** | Borrador |

---

## Tabla de Contenidos

1. [Identificador del Plan de Pruebas](#1-identificador-del-plan-de-pruebas)
2. [Referencias](#2-referencias)
3. [Introducci√≥n](#3-introducci√≥n)
4. [Elementos de Prueba](#4-elementos-de-prueba)
5. [Caracter√≠sticas a Probar](#5-caracter√≠sticas-a-probar)
6. [Caracter√≠sticas que No se Probar√°n](#6-caracter√≠sticas-que-no-se-probar√°n)
7. [Aproximaci√≥n](#7-aproximaci√≥n)
8. [Criterios de √âxito/Fallo](#8-criterios-de-√©xitofallo)
9. [Criterios de Suspensi√≥n y Reanudaci√≥n](#9-criterios-de-suspensi√≥n-y-reanudaci√≥n)
10. [Entregables de Prueba](#10-entregables-de-prueba)
11. [Tareas de Prueba](#11-tareas-de-prueba)
12. [Necesidades del Entorno](#12-necesidades-del-entorno)
13. [Responsabilidades](#13-responsabilidades)
14. [Cronograma](#14-cronograma)
15. [Riesgos y Contingencias](#15-riesgos-y-contingencias)
16. [Aprobaciones](#16-aprobaciones)

---

## 1. Identificador del Plan de Pruebas

**ID del Plan:** TP-CHATBOT-DCCO-001  
**Nombre del Proyecto:** Sistema de Chatbot Acad√©mico DCCO/ESPE  
**Versi√≥n del Software:** 1.0  
**Entorno Objetivo:** Producci√≥n  

### 1.1 Prop√≥sito del Documento

Este documento define la estrategia, objetivos, cronograma, estimaciones, recursos y aproximaci√≥n para las actividades de prueba del Sistema de Chatbot Acad√©mico del Departamento de Ciencias de la Computaci√≥n (DCCO) de la Universidad ESPE.

### 1.2 Audiencia Objetivo

- Equipo de Desarrollo de Software
- Arquitectos de Software
- Especialistas en QA/Testing
- Project Manager
- Stakeholders del DCCO

---

## 2. Referencias

### 2.1 Documentos de Referencia

| **Documento** | **Versi√≥n** | **Ubicaci√≥n** |
|---|---|---|
| Especificaci√≥n de Requisitos de Software | 1.0 | [SRS-CHATBOT-001] |
| Documento de Arquitectura de Software | 1.0 | [SAD-CHATBOT-001] |
| Manual de Usuario | 1.0 | [UM-CHATBOT-001] |
| Pol√≠tica de Calidad de Software | 2.1 | [QP-ESPE-021] |

### 2.2 Est√°ndares Aplicables

- **IEEE 829-2008:** Standard for Software and System Test Documentation
- **ISO/IEC 25010:** Systems and software Quality Requirements and Evaluation (SQuaRE)
- **ISO/IEC/IEEE 29119:** Software Testing Standard
- **ISTQB Foundation Level:** Testing Best Practices

---

## 3. Introducci√≥n

### 3.1 Descripci√≥n del Sistema

El Sistema de Chatbot Acad√©mico DCCO/ESPE es una aplicaci√≥n web basada en inteligencia artificial que proporciona asistencia automatizada a estudiantes y personal del Departamento de Ciencias de la Computaci√≥n. El sistema integra:

- **Backend:** Django REST Framework
- **Base de Datos:** SQLite (desarrollo), PostgreSQL (producci√≥n)
- **Inteligencia Artificial:** OpenAI GPT-3.5-turbo
- **Sistema RAG:** Firebase Firestore con embeddings vectoriales
- **B√∫squeda:** Vector store con sentence-transformers
- **Autenticaci√≥n:** Token-based authentication

### 3.2 Objetivos de las Pruebas

#### 3.2.1 Objetivos Primarios
- Verificar que el sistema cumple con los requisitos funcionales especificados
- Validar la integraci√≥n correcta entre componentes (Django, OpenAI, Firebase)
- Asegurar la calidad de las respuestas del chatbot en contexto acad√©mico
- Garantizar la seguridad y privacidad de los datos

#### 3.2.2 Objetivos Secundarios
- Evaluar el rendimiento bajo cargas normales y pico
- Verificar la usabilidad de las interfaces de usuario
- Validar la mantenibilidad del c√≥digo
- Asegurar la compatibilidad con diferentes navegadores y dispositivos

### 3.3 Alcance de las Pruebas

#### 3.3.1 Dentro del Alcance
- Funcionalidades del API REST
- Procesamiento de lenguaje natural y respuestas del chatbot
- Integraci√≥n con servicios externos (OpenAI, Firebase)
- Seguridad de la aplicaci√≥n
- Rendimiento y escalabilidad
- Calidad del c√≥digo fuente

#### 3.3.2 Fuera del Alcance
- Infraestructura de servidores y red
- Servicios de terceros (OpenAI API, Firebase infrastructure)
- Interfaces de usuario frontend (si las hay)
- Migraci√≥n de datos hist√≥ricos

---

## 4. Elementos de Prueba

### 4.1 Componentes del Software

| **Componente** | **Versi√≥n** | **Descripci√≥n** | **Criticidad** |
|---|---|---|---|
| chatbot.views | 1.0 | API principal del chatbot | Alta |
| firebase_embeddings | 1.0 | Sistema RAG con embeddings | Alta |
| firebase_service | 1.0 | Gesti√≥n de datos Firebase | Alta |
| vector_store | 1.0 | B√∫squeda vectorial local | Media |
| authentication | 1.0 | Sistema de autenticaci√≥n | Alta |
| simple_views | 1.0 | Vistas de gesti√≥n FAQ | Media |
| document_loader | 1.0 | Carga de documentos PDF | Baja |

### 4.2 Configuraciones de Prueba

| **Configuraci√≥n** | **Descripci√≥n** | **Prop√≥sito** |
|---|---|---|
| Desarrollo | Entorno local con SQLite | Pruebas unitarias e integraci√≥n |
| Staging | Servidor de pruebas con PostgreSQL | Pruebas de sistema y aceptaci√≥n |
| Producci√≥n | Servidor productivo | Pruebas de humo y monitoreo |

---

## 5. Caracter√≠sticas a Probar

### 5.1 Funcionalidades Principales

#### 5.1.1 Procesamiento de Consultas (Prioridad: Alta)
- **F001:** Recepci√≥n y validaci√≥n de preguntas de usuarios
- **F002:** Detecci√≥n de contexto acad√©mico vs. fuera de contexto
- **F003:** B√∫squeda en base de conocimiento Firebase
- **F004:** Reformulaci√≥n de respuestas con OpenAI
- **F005:** Generaci√≥n de respuestas para preguntas no documentadas

#### 5.1.2 Gesti√≥n de Base de Conocimiento (Prioridad: Media)
- **F006:** Agregar nuevas entradas FAQ
- **F007:** Modificar entradas existentes
- **F008:** Validaci√≥n de duplicados
- **F009:** Gesti√≥n de embeddings autom√°tica

#### 5.1.3 Autenticaci√≥n y Autorizaci√≥n (Prioridad: Alta)
- **F010:** Autenticaci√≥n por token para gesti√≥n
- **F011:** Acceso p√∫blico para consultas
- **F012:** Validaci√≥n de permisos

### 5.2 Caracter√≠sticas No Funcionales

#### 5.2.1 Rendimiento (Prioridad: Alta)
- **NF001:** Tiempo de respuesta < 3 segundos para 95% de consultas
- **NF002:** Capacidad de 100 usuarios concurrentes
- **NF003:** Disponibilidad del sistema > 99%

#### 5.2.2 Seguridad (Prioridad: Alta)
- **NF004:** Protecci√≥n contra inyecci√≥n SQL
- **NF005:** Protecci√≥n contra ataques XSS
- **NF006:** Validaci√≥n de entrada de datos
- **NF007:** Logging de accesos y errores

#### 5.2.3 Usabilidad (Prioridad: Media)
- **NF008:** Respuestas claras y relevantes
- **NF009:** Manejo adecuado de errores
- **NF010:** Retroalimentaci√≥n apropiada al usuario

#### 5.2.4 Mantenibilidad (Prioridad: Media)
- **NF011:** C√≥digo cumple est√°ndares PEP 8
- **NF012:** Cobertura de pruebas > 80%
- **NF013:** Documentaci√≥n de c√≥digo adecuada

---

## 6. Caracter√≠sticas que No se Probar√°n

### 6.1 Componentes Excluidos

- **Infraestructura:** Configuraci√≥n de servidores, red, DNS
- **Servicios Externos:** Funcionamiento interno de OpenAI API y Firebase
- **Navegadores Legacy:** Internet Explorer, versiones obsoletas
- **Dispositivos Espec√≠ficos:** Hardware especializado o muy antiguo

### 6.2 Justificaci√≥n de Exclusiones

Las exclusiones se basan en:
- Componentes fuera del control del equipo de desarrollo
- Tecnolog√≠as obsoletas o no soportadas
- Limitaciones de tiempo y recursos
- Riesgos aceptables para el negocio

---

## 7. Aproximaci√≥n

### 7.1 Estrategia General

La estrategia de pruebas sigue un enfoque **basado en riesgos** con implementaci√≥n de **testing en pir√°mide**:

```
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ     E2E     ‚îÇ  (20%)
                ‚îÇ  Manual/API ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   ‚îÇ Integration ‚îÇ   ‚îÇ  (30%)
            ‚îÇ   ‚îÇ  Component  ‚îÇ   ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   ‚îÇ   ‚îÇ    Unit     ‚îÇ   ‚îÇ   ‚îÇ  (50%)
        ‚îÇ   ‚îÇ   ‚îÇ   Tests     ‚îÇ   ‚îÇ   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îò
```

### 7.2 Tipos de Prueba

#### 7.2.1 Pruebas Est√°ticas
- **Revisi√≥n de C√≥digo:** An√°lisis manual de c√≥digo cr√≠tico
- **An√°lisis Est√°tico:** Herramientas automatizadas (pylint, flake8)
- **Revisi√≥n de Documentaci√≥n:** Verificaci√≥n de completitud y precisi√≥n

#### 7.2.2 Pruebas Din√°micas

**Pruebas de Caja Blanca:**
- Pruebas unitarias con pytest
- An√°lisis de cobertura de c√≥digo
- Pruebas de flujo de control

**Pruebas de Caja Negra:**
- Pruebas funcionales basadas en requisitos
- Pruebas de partici√≥n de equivalencia
- Pruebas de valores l√≠mite
- Pruebas de casos de uso

**Pruebas de Caja Gris:**
- Pruebas de integraci√≥n de componentes
- Pruebas de API con conocimiento interno

### 7.3 Niveles de Prueba

#### 7.3.1 Pruebas Unitarias (50% del esfuerzo)
- **Herramientas:** pytest, unittest, mock
- **Cobertura:** 80% m√≠nimo
- **Automatizaci√≥n:** 100%

#### 7.3.2 Pruebas de Integraci√≥n (30% del esfuerzo)
- **Herramientas:** pytest-django, requests
- **Enfoque:** Big Bang y Bottom-up
- **Automatizaci√≥n:** 90%

#### 7.3.3 Pruebas de Sistema (15% del esfuerzo)
- **Herramientas:** Postman, curl scripts
- **Enfoque:** End-to-end scenarios
- **Automatizaci√≥n:** 70%

#### 7.3.4 Pruebas de Aceptaci√≥n (5% del esfuerzo)
- **Herramientas:** Manual testing, user scenarios
- **Enfoque:** Business requirements validation
- **Automatizaci√≥n:** 30%

### 7.4 Herramientas de Prueba

#### 7.4.1 Framework y Librer√≠as
```python
# Core testing framework
pytest==7.4.0
pytest-django==4.5.2
pytest-cov==4.1.0
pytest-mock==3.11.1

# Test data generation
factory-boy==3.3.0
faker==19.3.0

# API testing
requests==2.31.0
responses==0.23.1
```

#### 7.4.2 An√°lisis de Calidad
```python
# Static analysis
pylint==2.17.4
flake8==6.0.0
mypy==1.5.1
black==23.7.0

# Security analysis
bandit==1.7.5
safety==2.3.5
```

#### 7.4.3 M√©tricas y Reportes
```python
# Coverage and reporting
coverage==7.2.7
pytest-html==3.2.0
pytest-json-report==1.5.0
```

---

## 8. Criterios de √âxito/Fallo

### 8.1 Criterios de √âxito

#### 8.1.1 Criterios Funcionales
- ‚úÖ **100%** de casos de prueba cr√≠ticos pasan
- ‚úÖ **95%** de casos de prueba totales pasan
- ‚úÖ **90%** de precisi√≥n en respuestas acad√©micas
- ‚úÖ **0** defectos cr√≠ticos abiertos
- ‚úÖ **‚â§ 2** defectos altos abiertos

#### 8.1.2 Criterios No Funcionales
- ‚úÖ **‚â• 80%** cobertura de c√≥digo
- ‚úÖ **‚â• 8.0/10** score de pylint
- ‚úÖ **< 3 segundos** tiempo de respuesta promedio
- ‚úÖ **0** vulnerabilidades cr√≠ticas o altas
- ‚úÖ **100%** disponibilidad durante pruebas

#### 8.1.3 Criterios de Calidad
- ‚úÖ **0** violaciones de est√°ndares de codificaci√≥n cr√≠ticas
- ‚úÖ **‚â• 90%** conformidad con requisitos
- ‚úÖ **100%** de documentaci√≥n de casos de prueba ejecutados

### 8.2 Criterios de Fallo

#### 8.2.1 Fallo Cr√≠tico
- ‚ùå Sistema no puede procesar consultas b√°sicas
- ‚ùå P√©rdida o corrupci√≥n de datos
- ‚ùå Vulnerabilidades de seguridad cr√≠ticas
- ‚ùå Ca√≠da del sistema sin posibilidad de recuperaci√≥n

#### 8.2.2 Fallo Alto
- ‚ùå > 10% de casos de prueba cr√≠ticos fallan
- ‚ùå Tiempo de respuesta > 10 segundos constantemente
- ‚ùå Imposibilidad de agregar nuevas FAQs
- ‚ùå Respuestas incorrectas > 20% del tiempo

---

## 9. Criterios de Suspensi√≥n y Reanudaci√≥n

### 9.1 Criterios de Suspensi√≥n

Las pruebas se suspender√°n si:

1. **Build Inestable:** > 50% de casos de prueba fallan debido a problemas de build
2. **Entorno Inaccesible:** Servicios cr√≠ticos (Firebase, OpenAI) no disponibles > 4 horas
3. **Datos Corruptos:** Base de datos de pruebas corrupta sin posibilidad de restauraci√≥n
4. **Recursos Insuficientes:** Falta de personal clave por > 2 d√≠as consecutivos
5. **Bloqueos Cr√≠ticos:** Defectos que impiden continuar con > 70% de casos de prueba

### 9.2 Criterios de Reanudaci√≥n

Las pruebas se reanudar√°n cuando:

1. **Build Estable:** < 10% de fallos en casos de prueba b√°sicos
2. **Entorno Disponible:** Todos los servicios externos accesibles y estables
3. **Datos Restaurados:** Base de datos de pruebas restaurada y validada
4. **Recursos Disponibles:** Personal clave disponible para continuar
5. **Bloqueos Resueltos:** Defectos cr√≠ticos resueltos y verificados

---

## 10. Entregables de Prueba

### 10.1 Documentos de Planificaci√≥n

| **Documento** | **Responsable** | **Fecha Entrega** |
|---|---|---|
| Plan de Pruebas | QA Lead | Semana 1 |
| Especificaci√≥n de Casos de Prueba | QA Engineer | Semana 2 |
| Plan de Datos de Prueba | QA Engineer | Semana 2 |
| Configuraci√≥n de Entorno de Pruebas | DevOps | Semana 1 |

### 10.2 Artefactos de Ejecuci√≥n

| **Artefacto** | **Formato** | **Frecuencia** |
|---|---|---|
| Reporte de Ejecuci√≥n Diario | HTML/JSON | Diario |
| Reporte de Cobertura | HTML | Semanal |
| Reporte de Defectos | Tracking System | Continuo |
| M√©tricas de Calidad | Dashboard | Tiempo Real |

### 10.3 C√≥digo de Pruebas

```
tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ test_views.py
‚îÇ   ‚îú‚îÄ‚îÄ test_firebase_service.py
‚îÇ   ‚îú‚îÄ‚îÄ test_embeddings.py
‚îÇ   ‚îî‚îÄ‚îÄ test_authentication.py
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ test_api_endpoints.py
‚îÇ   ‚îú‚îÄ‚îÄ test_firebase_integration.py
‚îÇ   ‚îî‚îÄ‚îÄ test_openai_integration.py
‚îú‚îÄ‚îÄ system/
‚îÇ   ‚îú‚îÄ‚îÄ test_end_to_end.py
‚îÇ   ‚îî‚îÄ‚îÄ test_performance.py
‚îú‚îÄ‚îÄ security/
‚îÇ   ‚îú‚îÄ‚îÄ test_injection.py
‚îÇ   ‚îî‚îÄ‚îÄ test_xss.py
‚îî‚îÄ‚îÄ fixtures/
    ‚îú‚îÄ‚îÄ test_data.json
    ‚îî‚îÄ‚îÄ mock_responses.py
```

---

## 11. Tareas de Prueba

### 11.1 Fase de Preparaci√≥n (Semana 1)

#### 11.1.1 Configuraci√≥n del Entorno
- **T001:** Configurar entorno de pruebas local
- **T002:** Configurar entorno de pruebas staging
- **T003:** Instalar herramientas de testing
- **T004:** Configurar CI/CD pipeline

#### 11.1.2 Preparaci√≥n de Datos
- **T005:** Crear datos de prueba base
- **T006:** Configurar mocks para servicios externos
- **T007:** Preparar datasets de FAQs de prueba
- **T008:** Validar conectividad con servicios

### 11.2 Fase de Pruebas Unitarias (Semana 2-3)

#### 11.2.1 Desarrollo de Casos de Prueba
- **T009:** Escribir tests para views.py
- **T010:** Escribir tests para firebase_service.py
- **T011:** Escribir tests para firebase_embeddings.py
- **T012:** Escribir tests para authentication.py
- **T013:** Escribir tests para vector_store.py

#### 11.2.2 Ejecuci√≥n y An√°lisis
- **T014:** Ejecutar suite de pruebas unitarias
- **T015:** Analizar cobertura de c√≥digo
- **T016:** Refactorizar tests basado en resultados
- **T017:** Documentar casos de prueba

### 11.3 Fase de Pruebas de Integraci√≥n (Semana 3-4)

#### 11.3.1 Integraci√≥n de Componentes
- **T018:** Probar integraci√≥n Django-Firebase
- **T019:** Probar integraci√≥n Django-OpenAI
- **T020:** Probar flujo completo de consultas
- **T021:** Probar gesti√≥n de FAQs end-to-end

#### 11.3.2 Integraci√≥n de Sistema
- **T022:** Probar APIs REST completos
- **T023:** Probar autenticaci√≥n y autorizaci√≥n
- **T024:** Probar manejo de errores
- **T025:** Probar logging y monitoreo

### 11.4 Fase de Pruebas No Funcionales (Semana 4-5)

#### 11.4.1 Pruebas de Rendimiento
- **T026:** Ejecutar pruebas de carga
- **T027:** Probar tiempo de respuesta
- **T028:** Analizar uso de memoria
- **T029:** Probar escalabilidad

#### 11.4.2 Pruebas de Seguridad
- **T030:** Ejecutar an√°lisis de vulnerabilidades
- **T031:** Probar inyecci√≥n SQL/NoSQL
- **T032:** Probar ataques XSS
- **T033:** Validar autenticaci√≥n y autorizaci√≥n

### 11.5 Fase de Pruebas Especializadas (Semana 5)

#### 11.5.1 Pruebas de IA/ML
- **T034:** Validar precisi√≥n de respuestas
- **T035:** Probar detecci√≥n de contexto
- **T036:** Validar reformulaci√≥n de respuestas
- **T037:** Probar casos edge de IA

#### 11.5.2 Pruebas de Usabilidad
- **T038:** Validar claridad de respuestas
- **T039:** Probar manejo de errores
- **T040:** Validar experiencia de usuario

---

## 12. Necesidades del Entorno

### 12.1 Entorno de Hardware

#### 12.1.1 Servidor de Desarrollo
- **CPU:** 4 cores, 2.5GHz m√≠nimo
- **RAM:** 8GB m√≠nimo, 16GB recomendado
- **Almacenamiento:** 100GB SSD
- **Red:** Conexi√≥n estable 100Mbps

#### 12.1.2 Servidor de Staging
- **CPU:** 8 cores, 3.0GHz
- **RAM:** 16GB m√≠nimo, 32GB recomendado
- **Almacenamiento:** 200GB SSD
- **Red:** Conexi√≥n estable 1Gbps

### 12.2 Entorno de Software

#### 12.2.1 Sistema Operativo
- **SO:** Ubuntu 20.04 LTS o superior
- **Python:** 3.11+
- **Base de Datos:** PostgreSQL 14+ (staging), SQLite 3.40+ (desarrollo)

#### 12.2.2 Dependencias Externas
- **OpenAI API:** Acceso con API key v√°lida
- **Firebase:** Proyecto configurado con Firestore
- **Internet:** Acceso estable para servicios cloud

### 12.3 Herramientas de Prueba

```bash
# Testing framework
pip install pytest pytest-django pytest-cov pytest-mock

# Code quality
pip install pylint flake8 mypy black bandit safety

# Test utilities
pip install factory-boy faker responses requests-mock

# Performance testing
pip install locust

# Security testing
pip install bandit safety owasp-zap-python
```

### 12.4 Configuraci√≥n de Entorno

#### 12.4.1 Variables de Entorno
```bash
# Django configuration
DJANGO_SETTINGS_MODULE=chatbot_api.settings
SECRET_KEY=test-secret-key-for-testing
DEBUG=True

# Database
DATABASE_URL=postgresql://user:pass@localhost/testdb

# External services
OPENAI_API_KEY=sk-test-key
FIREBASE_PROJECT_ID=chatbot-dcco-test
GOOGLE_APPLICATION_CREDENTIALS=path/to/test-credentials.json

# Testing specific
TESTING=True
PYTEST_CURRENT_TEST=1
```

#### 12.4.2 Configuraci√≥n de CI/CD
```yaml
# .github/workflows/tests.yml
name: Test Suite
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.11, 3.12]
    
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-testing.txt
    
    - name: Run tests
      run: |
        pytest --cov=chatbot --cov-report=xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
```

---

## 13. Responsabilidades

### 13.1 Roles y Responsabilidades

#### 13.1.1 QA Lead
**Responsable:** [Nombre del QA Lead]
- Planificaci√≥n y coordinaci√≥n de actividades de prueba
- Revisi√≥n y aprobaci√≥n de casos de prueba
- Gesti√≥n de defectos y m√©tricas de calidad
- Comunicaci√≥n con stakeholders

**Entregables:**
- Plan de pruebas
- Reportes de estado
- M√©tricas de calidad
- Recomendaciones de mejora

#### 13.1.2 QA Engineer
**Responsable:** [Nombre del QA Engineer]
- Dise√±o y desarrollo de casos de prueba
- Ejecuci√≥n de pruebas manuales y automatizadas
- Reporte y seguimiento de defectos
- Mantenimiento de scripts de prueba

**Entregables:**
- Casos de prueba detallados
- Scripts de automatizaci√≥n
- Reportes de defectos
- Resultados de ejecuci√≥n

#### 13.1.3 Desarrollador Senior
**Responsable:** [Nombre del Developer]
- Soporte t√©cnico para entorno de pruebas
- Revisi√≥n de casos de prueba cr√≠ticos
- Resoluci√≥n de defectos
- Implementaci√≥n de mejoras de testabilidad

**Entregables:**
- C√≥digo con unit tests
- Documentaci√≥n t√©cnica
- Fixes de defectos
- Mejoras de arquitectura

#### 13.1.4 DevOps Engineer
**Responsable:** [Nombre del DevOps]
- Configuraci√≥n de entornos de prueba
- Implementaci√≥n de CI/CD pipeline
- Monitoreo de entornos
- Backup y restauraci√≥n de datos

**Entregables:**
- Entornos configurados
- Pipeline de CI/CD
- Scripts de deployment
- Procedimientos de backup

### 13.2 Matriz RACI

| **Actividad** | **QA Lead** | **QA Eng** | **Dev** | **DevOps** | **PM** |
|---|---|---|---|---|---|
| Plan de Pruebas | R,A | C | C | C | I |
| Casos de Prueba | A | R | C | I | I |
| Entorno de Pruebas | C | C | C | R,A | I |
| Ejecuci√≥n de Pruebas | A | R | C | I | I |
| Reporte de Defectos | A | R | C | I | I |
| Resoluci√≥n de Defectos | C | C | R,A | C | I |
| Reportes de Estado | R,A | C | I | I | C |

**Leyenda:** R=Responsable, A=Aprobador, C=Consultado, I=Informado

---

## 14. Cronograma

### 14.1 Cronograma Maestro

| **Fase** | **Duraci√≥n** | **Fecha Inicio** | **Fecha Fin** | **Hitos** |
|---|---|---|---|---|
| Planificaci√≥n | 1 semana | 13/08/2025 | 20/08/2025 | Plan aprobado |
| Preparaci√≥n | 1 semana | 20/08/2025 | 27/08/2025 | Entorno listo |
| Pruebas Unitarias | 2 semanas | 27/08/2025 | 10/09/2025 | 80% cobertura |
| Pruebas Integraci√≥n | 1.5 semanas | 10/09/2025 | 20/09/2025 | APIs validadas |
| Pruebas Sistema | 1 semana | 20/09/2025 | 27/09/2025 | E2E completos |
| Pruebas No Funcionales | 1 semana | 27/09/2025 | 04/10/2025 | SLAs validados |
| Cierre | 0.5 semanas | 04/10/2025 | 08/10/2025 | Reporte final |

### 14.2 Cronograma Detallado

#### 14.2.1 Semana 1: Planificaci√≥n (13-20 Agosto)
| **D√≠a** | **Actividades** | **Entregables** | **Responsable** |
|---|---|---|---|
| Lunes | Kickoff, revisi√≥n de requisitos | Acta de reuni√≥n | QA Lead |
| Martes | An√°lisis de riesgos, estimaciones | Matriz de riesgos | QA Lead |
| Mi√©rcoles | Dise√±o de estrategia de pruebas | Plan preliminar | QA Lead |
| Jueves | Revisi√≥n con stakeholders | Plan revisado | QA Lead |
| Viernes | Aprobaci√≥n y comunicaci√≥n | Plan aprobado | QA Lead |

#### 14.2.2 Semana 2: Preparaci√≥n (20-27 Agosto)
| **D√≠a** | **Actividades** | **Entregables** | **Responsable** |
|---|---|---|---|
| Lunes | Setup entorno desarrollo | Entorno dev listo | DevOps |
| Martes | Setup entorno staging | Entorno staging listo | DevOps |
| Mi√©rcoles | Instalaci√≥n herramientas | Herramientas configuradas | QA Eng |
| Jueves | Preparaci√≥n datos de prueba | Datasets listos | QA Eng |
| Viernes | Validaci√≥n y smoke tests | Entorno validado | QA Eng |

#### 14.2.3 Semanas 3-4: Pruebas Unitarias (27 Ago - 10 Sep)
| **Semana** | **Foco** | **Meta** | **Criterio √âxito** |
|---|---|---|---|
| Semana 3 | Core functionality | 40% cobertura | Tests views, firebase |
| Semana 4 | Edge cases, refactoring | 80% cobertura | Suite completa |

#### 14.2.4 Semana 5-6: Integraci√≥n y Sistema (10-27 Sep)
| **Semana** | **Foco** | **Meta** | **Criterio √âxito** |
|---|---|---|---|
| Semana 5 | Component integration | APIs funcionando | End-to-end b√°sico |
| Semana 6 | System testing | Flujos completos | Scenarios cr√≠ticos |

#### 14.2.5 Semana 7: No Funcionales (27 Sep - 4 Oct)
| **Tipo** | **Duraci√≥n** | **Meta** | **Criterio √âxito** |
|---|---|---|---|
| Performance | 2 d√≠as | < 3s response | SLA cumplido |
| Security | 2 d√≠as | 0 critical vulns | Scan limpio |
| Usability | 1 d√≠a | Responses claras | Feedback positivo |

### 14.3 Dependencias Cr√≠ticas

| **Dependencia** | **Impacto** | **Contingencia** |
|---|---|---|
| Acceso OpenAI API | Alto | Usar mocks temporalmente |
| Firebase disponibilidad | Alto | Base datos local backup |
| Servidor staging | Medio | Usar entorno local |
| Personal QA | Alto | Training cross-functional |

---

## 15. Riesgos y Contingencias

### 15.1 Identificaci√≥n de Riesgos

#### 15.1.1 Riesgos T√©cnicos

| **ID** | **Riesgo** | **Probabilidad** | **Impacto** | **Nivel** |
|---|---|---|---|---|
| RT001 | API OpenAI inaccesible durante pruebas | Media | Alto | Alto |
| RT002 | Firebase limits excedidos | Baja | Alto | Medio |
| RT003 | Cambios arquitectura tard√≠os | Media | Alto | Alto |
| RT004 | Performance del modelo IA variable | Alta | Medio | Alto |
| RT005 | Datos de prueba insuficientes | Baja | Medio | Bajo |

#### 15.1.2 Riesgos de Proyecto

| **ID** | **Riesgo** | **Probabilidad** | **Impacto** | **Nivel** |
|---|---|---|---|---|
| RP001 | Retrasos en desarrollo | Media | Alto | Alto |
| RP002 | Recursos QA insuficientes | Baja | Alto | Medio |
| RP003 | Cambios de requisitos | Media | Medio | Medio |
| RP004 | Entorno staging inestable | Media | Medio | Medio |
| RP005 | Falta documentaci√≥n t√©cnica | Alta | Bajo | Medio |

#### 15.1.3 Riesgos de Calidad

| **ID** | **Riesgo** | **Probabilidad** | **Impacto** | **Nivel** |
|---|---|---|---|---|
| RQ001 | Casos de prueba incompletos | Media | Alto | Alto |
| RQ002 | Automatizaci√≥n insuficiente | Media | Medio | Medio |
| RQ003 | Cobertura de c√≥digo baja | Alta | Medio | Alto |
| RQ004 | Defectos no detectados | Baja | Alto | Medio |
| RQ005 | False positives en tests | Media | Bajo | Bajo |

### 15.2 Estrategias de Mitigaci√≥n

#### 15.2.1 Mitigaci√≥n de Riesgos T√©cnicos

**RT001 - API OpenAI inaccesible:**
- **Prevenci√≥n:** Monitoreo proactivo de status
- **Mitigaci√≥n:** Mocks comprehensivos para todas las funciones
- **Contingencia:** Tests offline con respuestas pre-grabadas
- **Responsable:** DevOps Engineer

**RT003 - Cambios arquitectura tard√≠os:**
- **Prevenci√≥n:** Freeze arquitectural despu√©s de Semana 1
- **Mitigaci√≥n:** Tests modulares adaptables
- **Contingencia:** Re-planning con tiempo adicional
- **Responsable:** QA Lead + Arquitecto

**RT004 - Performance IA variable:**
- **Prevenci√≥n:** Baseline de performance establecido
- **Mitigaci√≥n:** Tests estad√≠sticos (percentiles)
- **Contingencia:** Criterios flexibles documentados
- **Responsable:** QA Engineer

#### 15.2.2 Mitigaci√≥n de Riesgos de Proyecto

**RP001 - Retrasos en desarrollo:**
- **Prevenci√≥n:** Checkpoints semanales
- **Mitigaci√≥n:** Priorizaci√≥n de tests cr√≠ticos
- **Contingencia:** Scope reduction documentado
- **Responsable:** QA Lead + PM

**RP002 - Recursos QA insuficientes:**
- **Prevenci√≥n:** Cross-training desarrolladores
- **Mitigaci√≥n:** Automatizaci√≥n m√°xima
- **Contingencia:** Outsourcing temporal
- **Responsable:** QA Lead

#### 15.2.3 Mitigaci√≥n de Riesgos de Calidad

**RQ001 - Casos de prueba incompletos:**
- **Prevenci√≥n:** Peer review obligatorio
- **Mitigaci√≥n:** Template estandarizado
- **Contingencia:** Audit externo
- **Responsable:** QA Engineer

**RQ003 - Cobertura c√≥digo baja:**
- **Prevenci√≥n:** Gates autom√°ticos en CI/CD
- **Mitigaci√≥n:** Identificaci√≥n gaps diaria
- **Contingencia:** Sprint adicional de testing
- **Responsable:** QA Engineer + Developer

### 15.3 Plan de Contingencia

#### 15.3.1 Escenario: Retraso Cr√≠tico (>1 semana)

**Trigger:** Desarrollo atrasado >5 d√≠as
**Acci√≥n Inmediata:**
1. Reuni√≥n emergencia stakeholders
2. Re-evaluar scope cr√≠tico vs. nice-to-have
3. Priorizar tests para funcionalidad core
4. Comunicar impacto a usuario final

**Responsable:** QA Lead + PM

#### 15.3.2 Escenario: Falla Servicios Externos

**Trigger:** OpenAI/Firebase down >4 horas
**Acci√≥n Inmediata:**
1. Activar modo "tests offline"
2. Usar mocks y data sint√©tica
3. Continuar con tests unitarios
4. Re-schedule tests integraci√≥n

**Responsable:** DevOps + QA Engineer

#### 15.3.3 Escenario: Defectos Cr√≠ticos Masivos

**Trigger:** >50% tests fallando
**Acci√≥n Inmediata:**
1. Stop testing, evaluar build
2. Triage de defectos por severidad
3. Focus en show-stoppers √∫nicamente
4. Daily stand-ups hasta resoluci√≥n

**Responsable:** QA Lead + Development Lead

---

## 16. Aprobaciones

### 16.1 Revisi√≥n del Documento

| **Rol** | **Nombre** | **Fecha Revisi√≥n** | **Estado** | **Comentarios** |
|---|---|---|---|---|
| QA Lead | [Nombre] | [DD/MM/YYYY] | ‚è≥ Pendiente | |
| Tech Lead | [Nombre] | [DD/MM/YYYY] | ‚è≥ Pendiente | |
| Project Manager | [Nombre] | [DD/MM/YYYY] | ‚è≥ Pendiente | |
| Product Owner | [Nombre] | [DD/MM/YYYY] | ‚è≥ Pendiente | |

### 16.2 Aprobaci√≥n Formal

#### 16.2.1 Criterios de Aprobaci√≥n
- ‚úÖ Revisi√≥n t√©cnica completada sin observaciones cr√≠ticas
- ‚úÖ Alineaci√≥n con objetivos de negocio confirmada
- ‚úÖ Recursos y cronograma validados como factibles
- ‚úÖ Riesgos identificados y mitigaciones aceptables
- ‚úÖ Stakeholders informados y comprometidos

#### 16.2.2 Firmas de Aprobaci√≥n

| **Rol** | **Nombre** | **Firma** | **Fecha** |
|---|---|---|---|
| **QA Manager** | [Nombre] | ________________ | [DD/MM/YYYY] |
| **Development Manager** | [Nombre] | ________________ | [DD/MM/YYYY] |
| **Project Manager** | [Nombre] | ________________ | [DD/MM/YYYY] |
| **Product Owner** | [Nombre] | ________________ | [DD/MM/YYYY] |

### 16.3 Control de Versiones

| **Versi√≥n** | **Fecha** | **Autor** | **Descripci√≥n de Cambios** |
|---|---|---|---|
| 0.1 | 12/08/2025 | QA Team | Borrador inicial |
| 1.0 | [DD/MM/YYYY] | [Autor] | Primera versi√≥n aprobada |

### 16.4 Distribuci√≥n

Este documento ser√° distribuido a:
- ‚úÖ Equipo de Desarrollo
- ‚úÖ Equipo de QA
- ‚úÖ Project Management Office
- ‚úÖ Product Owner / Stakeholders
- ‚úÖ DevOps Team
- ‚úÖ Archivo del proyecto

---

## Anexos

### Anexo A: Plantillas de Casos de Prueba

#### A.1 Template de Caso de Prueba Funcional
```
ID: TC-[COMPONENT]-[NUMBER]
T√≠tulo: [Descripci√≥n breve del caso]
Precondiciones: [Estado inicial requerido]
Pasos:
1. [Acci√≥n espec√≠fica]
2. [Acci√≥n espec√≠fica]
3. [Acci√≥n espec√≠fica]
Resultado Esperado: [Resultado espec√≠fico y verificable]
Datos de Prueba: [Datos espec√≠ficos necesarios]
Prioridad: [Alta/Media/Baja]
Automatizable: [S√≠/No]
```

#### A.2 Template de Caso de Prueba de API
```
ID: TC-API-[ENDPOINT]-[NUMBER]
Endpoint: [URL del endpoint]
M√©todo: [GET/POST/PUT/DELETE]
Headers: [Headers requeridos]
Body: [JSON de request]
Status Code Esperado: [200/400/401/etc]
Response Body Esperado: [Estructura JSON]
Validaciones: [Campos a validar]
```

### Anexo B: Configuraci√≥n de Herramientas

#### B.1 Configuraci√≥n pytest.ini
```ini
[tool:pytest]
DJANGO_SETTINGS_MODULE = chatbot_api.settings.test
python_files = tests.py test_*.py *_tests.py
python_classes = Test*
python_functions = test_*
addopts = 
    --verbose
    --tb=short
    --cov=chatbot
    --cov-report=html
    --cov-report=term-missing
    --cov-fail-under=80
    --strict-markers
markers =
    unit: Unit tests
    integration: Integration tests
    api: API tests
    security: Security tests
    performance: Performance tests
```

#### B.2 Configuraci√≥n pylint
```ini
[MASTER]
load-plugins=pylint_django
django-settings-module=chatbot_api.settings

[MESSAGES CONTROL]
disable=missing-docstring,
        line-too-long,
        too-few-public-methods

[FORMAT]
max-line-length=120

[DESIGN]
max-args=10
max-attributes=15
```

### Anexo C: Scripts de Automatizaci√≥n

#### C.1 Script de Ejecuci√≥n Completa
```bash
#!/bin/bash
# run_test_suite.sh

echo "üöÄ Iniciando Suite Completa de Pruebas"

# 1. An√°lisis est√°tico
echo "üìä Ejecutando an√°lisis est√°tico..."
pylint chatbot/ --score=yes
flake8 chatbot/
bandit -r chatbot/

# 2. Pruebas unitarias
echo "üß™ Ejecutando pruebas unitarias..."
pytest tests/unit/ --cov=chatbot --cov-report=html

# 3. Pruebas de integraci√≥n
echo "üîó Ejecutando pruebas de integraci√≥n..."
pytest tests/integration/ -v

# 4. Pruebas de API
echo "üåê Ejecutando pruebas de API..."
pytest tests/api/ -v

# 5. Reporte final
echo "üìã Generando reporte final..."
coverage report
coverage html

echo "‚úÖ Suite completa ejecutada"
```

---

**Fin del Documento**

---

*Este plan de pruebas ha sido desarrollado siguiendo est√°ndares IEEE 829-2008 y ISO/IEC/IEEE 29119 para asegurar la calidad y completitud de las actividades de testing del Sistema de Chatbot Acad√©mico DCCO/ESPE.*
