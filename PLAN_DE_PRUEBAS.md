# Plan de Pruebas - Chatbot API DCCO/ESPE
## Proyecto de Aseguramiento de Calidad de Software

**Versi√≥n:** 1.0  
**Fecha:** 12 de Agosto de 2025  
**Autor:** [Tu Nombre]  
**Proyecto:** Sistema de Chatbot Acad√©mico DCCO/ESPE  

---

## üìã √çndice

1. [Resumen Ejecutivo](#1-resumen-ejecutivo)
2. [Alcance del Plan](#2-alcance-del-plan)
3. [Estrategia de Pruebas](#3-estrategia-de-pruebas)
4. [Tipos de Pruebas](#4-tipos-de-pruebas)
5. [Herramientas y Tecnolog√≠as](#5-herramientas-y-tecnolog√≠as)
6. [Criterios de Entrada y Salida](#6-criterios-de-entrada-y-salida)
7. [Plan de Ejecuci√≥n](#7-plan-de-ejecuci√≥n)
8. [Gesti√≥n de Defectos](#8-gesti√≥n-de-defectos)
9. [M√©tricas y Reportes](#9-m√©tricas-y-reportes)
10. [Cronograma](#10-cronograma)

---

## 1. Resumen Ejecutivo

### 1.1 Prop√≥sito
Este plan define la estrategia integral de pruebas para el sistema de Chatbot Acad√©mico del Departamento de Ciencias de la Computaci√≥n (DCCO) de la Universidad ESPE, garantizando la calidad, funcionalidad y rendimiento del sistema antes de su despliegue en producci√≥n.

### 1.2 Objetivos de Calidad
- **Funcionalidad:** 95% de respuestas correctas para preguntas acad√©micas v√°lidas
- **Rendimiento:** Tiempo de respuesta < 3 segundos para el 95% de consultas
- **Disponibilidad:** 99.5% de uptime del sistema
- **Seguridad:** 0 vulnerabilidades cr√≠ticas o altas
- **Cobertura de C√≥digo:** M√≠nimo 80% de cobertura en pruebas unitarias

### 1.3 Arquitectura del Sistema
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   Django API    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   Firebase      ‚îÇ
‚îÇ   (React/Web)   ‚îÇ    ‚îÇ   (ChatbotAPI)  ‚îÇ    ‚îÇ   (RAG System)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ   OpenAI GPT    ‚îÇ
                       ‚îÇ   (Reformulado) ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2. Alcance del Plan

### 2.1 Componentes Incluidos
- ‚úÖ **API REST Django** (chatbot/views.py)
- ‚úÖ **Sistema RAG Firebase** (firebase_embeddings.py)
- ‚úÖ **Integraci√≥n OpenAI** (consultar_llm_inteligente)
- ‚úÖ **B√∫squeda Vectorial** (vector_store.py)
- ‚úÖ **Endpoints de Gesti√≥n** (FAQManagementAPIView)
- ‚úÖ **Autenticaci√≥n y Autorizaci√≥n** (authentication.py)

### 2.2 Componentes Excluidos
- ‚ùå Frontend/UI (fuera del alcance del backend)
- ‚ùå Infraestructura de servidores (responsabilidad de DevOps)
- ‚ùå Migraci√≥n de datos hist√≥ricos

### 2.3 Ambiente de Pruebas
- **Desarrollo:** http://localhost:8000/
- **Staging:** http://74.235.218.90:8000/
- **Producci√≥n:** [Por definir]

---

## 3. Estrategia de Pruebas

### 3.1 Enfoque de Testing
**Estrategia:** Testing en Pir√°mide + Testing Basado en Riesgos

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ     E2E     ‚îÇ  (20%)
                    ‚îÇ  (Selenium) ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ   ‚îÇ Integration ‚îÇ   ‚îÇ  (30%)
                ‚îÇ   ‚îÇ  (Django)   ‚îÇ   ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   ‚îÇ   ‚îÇ    Unit     ‚îÇ   ‚îÇ   ‚îÇ  (50%)
            ‚îÇ   ‚îÇ   ‚îÇ  (pytest)   ‚îÇ   ‚îÇ   ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îò
```

### 3.2 Metodolog√≠a
- **Test-First Development:** Escribir pruebas antes del c√≥digo
- **Continuous Integration:** Ejecuci√≥n autom√°tica en cada commit
- **Risk-Based Testing:** Priorizar componentes cr√≠ticos

### 3.3 Criterios de Calidad
- **Funcional:** Todas las funcionalidades principales funcionan
- **No Funcional:** Rendimiento, seguridad y usabilidad aceptables
- **Regresi√≥n:** Nuevos cambios no rompen funcionalidad existente

---

## 4. Tipos de Pruebas

### 4.1 Pruebas Funcionales

#### 4.1.1 Pruebas Unitarias (50% del esfuerzo)
**Herramientas:** pytest, unittest  
**Cobertura Objetivo:** 80%  

**Componentes a Probar:**
- `chatbot/views.py` - L√≥gica del chatbot
- `firebase_embeddings.py` - Sistema RAG
- `vector_store.py` - B√∫squeda vectorial
- `authentication.py` - Autenticaci√≥n
- `firebase_service.py` - Gesti√≥n Firebase

**Casos de Prueba:**
```python
def test_consultar_openai_success()
def test_firebase_rag_integration()
def test_vector_search_similarity()
def test_academic_question_validation()
def test_context_filtering()
```

#### 4.1.2 Pruebas de Integraci√≥n (30% del esfuerzo)
**Herramientas:** Django TestCase, requests  

**Escenarios:**
- API + Firebase RAG
- API + OpenAI GPT
- API + Vector Store
- Sistema completo end-to-end

#### 4.1.3 Pruebas de API REST (20% del esfuerzo)
**Herramientas:** Postman, curl, requests  

**Endpoints a Probar:**
- `POST /chatbot/` - Consulta principal
- `POST /faq/manage/` - Gesti√≥n FAQs
- `GET /firebase/status/` - Estado del sistema
- `POST /faq/check-duplicate/` - Validaci√≥n duplicados

### 4.2 Pruebas No Funcionales

#### 4.2.1 Pruebas de Rendimiento
**Herramientas:** Apache JMeter, LoadRunner, wrk  

**M√©tricas:**
- Tiempo de respuesta promedio < 3s
- Throughput > 100 requests/minuto
- Uso de memoria < 512MB
- CPU utilization < 70%

#### 4.2.2 Pruebas de Seguridad
**Herramientas:** OWASP ZAP, Bandit, Safety  

**Verificaciones:**
- Inyecci√≥n SQL/NoSQL
- Cross-Site Scripting (XSS)
- Autenticaci√≥n y autorizaci√≥n
- Validaci√≥n de entrada
- Exposici√≥n de datos sensibles

#### 4.2.3 Pruebas de Usabilidad
**Herramientas:** Manual Testing, User Stories  

**Criterios:**
- Respuestas claras y √∫tiles
- Tiempo de respuesta aceptable
- Manejo de errores amigable

### 4.3 Pruebas Especializadas

#### 4.3.1 Pruebas de IA/ML
**Componente:** Reformulaci√≥n OpenAI + Firebase RAG  

**Casos de Prueba:**
- Precisi√≥n de respuestas acad√©micas
- Detecci√≥n de contexto correcto
- Reformulaci√≥n de respuestas
- Manejo de preguntas fuera de contexto

#### 4.3.2 Pruebas de Calidad de C√≥digo
**Herramientas:** pylint, flake8, black, mypy  

**M√©tricas:**
- Pylint score > 8.0/10
- 0 errores cr√≠ticos de flake8
- Cumplimiento PEP 8
- Type hints coverage > 70%

---

## 5. Herramientas y Tecnolog√≠as

### 5.1 Framework de Testing
```bash
# Instalaci√≥n de herramientas
pip install pytest pytest-django pytest-cov
pip install requests responses
pip install factory-boy faker
pip install pylint flake8 black mypy
pip install bandit safety
```

### 5.2 Herramientas por Categor√≠a

#### Pruebas Unitarias e Integraci√≥n
- **pytest** - Framework principal
- **Django TestCase** - Pruebas de Django
- **factory-boy** - Generaci√≥n de datos de prueba
- **responses** - Mock de APIs externas

#### Calidad de C√≥digo
- **pylint** - An√°lisis est√°tico
- **flake8** - Linting PEP 8
- **black** - Formateo autom√°tico
- **mypy** - Type checking

#### Seguridad
- **bandit** - An√°lisis de seguridad
- **safety** - Vulnerabilidades en dependencias
- **OWASP ZAP** - Pruebas de penetraci√≥n

#### Rendimiento
- **Apache JMeter** - Load testing
- **cProfile** - Profiling de Python
- **Django Debug Toolbar** - An√°lisis de queries

### 5.3 CI/CD Integration
```yaml
# .github/workflows/tests.yml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: |
          pytest --cov=chatbot
          pylint chatbot/
          flake8 chatbot/
          bandit -r chatbot/
```

---

## 6. Criterios de Entrada y Salida

### 6.1 Criterios de Entrada
**Para iniciar las pruebas, se debe cumplir:**
- ‚úÖ C√≥digo fuente estable en repositorio
- ‚úÖ Ambiente de pruebas configurado
- ‚úÖ Base de datos de pruebas disponible
- ‚úÖ APIs externas (OpenAI, Firebase) accesibles
- ‚úÖ Herramientas de testing instaladas

### 6.2 Criterios de Salida
**Para completar las pruebas, se debe lograr:**
- ‚úÖ 100% de casos de prueba ejecutados
- ‚úÖ 95% de casos de prueba pasando
- ‚úÖ 80% de cobertura de c√≥digo
- ‚úÖ 0 defectos cr√≠ticos abiertos
- ‚úÖ Pylint score > 8.0
- ‚úÖ 0 vulnerabilidades de seguridad altas/cr√≠ticas

---

## 7. Plan de Ejecuci√≥n

### 7.1 Fases de Testing

#### Fase 1: Setup y Preparaci√≥n (1 d√≠a)
- Configuraci√≥n de ambiente de pruebas
- Instalaci√≥n de herramientas
- Configuraci√≥n de datos de prueba

#### Fase 2: Pruebas Unitarias (3 d√≠as)
- Implementaci√≥n de pruebas unitarias
- Ejecuci√≥n y ajustes
- Reporte de cobertura

#### Fase 3: Pruebas de Integraci√≥n (2 d√≠as)
- Pruebas de API endpoints
- Integraci√≥n con servicios externos
- Pruebas de flujo completo

#### Fase 4: Pruebas No Funcionales (2 d√≠as)
- Pruebas de rendimiento
- An√°lisis de seguridad
- Pruebas de calidad de c√≥digo

#### Fase 5: Reporte y Documentaci√≥n (1 d√≠a)
- Consolidaci√≥n de resultados
- Reporte ejecutivo
- Recomendaciones

### 7.2 Cronograma Detallado

| D√≠a | Actividades | Entregables |
|-----|-------------|-------------|
| 1 | Setup inicial, configuraci√≥n | Ambiente listo |
| 2-4 | Pruebas unitarias | 80% cobertura |
| 5-6 | Pruebas de integraci√≥n | APIs validadas |
| 7-8 | Pruebas no funcionales | M√©tricas de calidad |
| 9 | Reporte final | Documento QA |

---

## 8. Gesti√≥n de Defectos

### 8.1 Clasificaci√≥n de Severidad

#### Cr√≠tica (P1)
- Sistema no funciona
- P√©rdida de datos
- Vulnerabilidades de seguridad cr√≠ticas

#### Alta (P2)
- Funcionalidad principal no trabaja
- Rendimiento inaceptable
- Errores de l√≥gica importantes

#### Media (P3)
- Funcionalidad secundaria afectada
- Problemas de usabilidad
- Inconsistencias menores

#### Baja (P4)
- Problemas cosm√©ticos
- Mejoras de c√≥digo
- Documentaci√≥n

### 8.2 Proceso de Gesti√≥n
1. **Detecci√≥n** ‚Üí Identificaci√≥n durante pruebas
2. **Registro** ‚Üí Documentaci√≥n en sistema de tracking
3. **Triaje** ‚Üí Asignaci√≥n de prioridad y responsable
4. **Resoluci√≥n** ‚Üí Desarrollo de fix
5. **Verificaci√≥n** ‚Üí Re-testing del defecto
6. **Cierre** ‚Üí Confirmaci√≥n de resoluci√≥n

---

## 9. M√©tricas y Reportes

### 9.1 M√©tricas de Pruebas

#### Cobertura de C√≥digo
```bash
pytest --cov=chatbot --cov-report=html
```
- **Objetivo:** 80% cobertura m√≠nima
- **Cr√≠tico:** Cubrir funciones principales del chatbot

#### Calidad de C√≥digo
```bash
pylint chatbot/ --score=yes
```
- **Objetivo:** Score > 8.0/10
- **M√©tricas:** Errores, warnings, convenciones

#### Rendimiento
- **Tiempo de respuesta:** < 3 segundos (95%)
- **Throughput:** > 100 requests/minuto
- **Memoria:** < 512MB uso promedio

### 9.2 Dashboards de Calidad

#### Dashboard Principal
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ DASHBOARD DE CALIDAD - CHATBOT DCCO                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Cobertura de C√≥digo:        [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 82%       ‚îÇ
‚îÇ Pylint Score:               [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 8.7/10    ‚îÇ
‚îÇ Pruebas Pasando:            [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 98%       ‚îÇ
‚îÇ Vulnerabilidades:           [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 0 Cr√≠ticas‚îÇ
‚îÇ Tiempo Respuesta Promedio:  [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 2.1s      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 9.3 Reportes Autom√°ticos

#### Reporte Diario
- Estado de build
- Pruebas ejecutadas/fallidas
- Nuevos defectos encontrados
- M√©tricas de rendimiento

#### Reporte Semanal
- Tendencias de calidad
- An√°lisis de defectos
- Recomendaciones de mejora
- Plan para pr√≥xima semana

---

## 10. Cronograma

### 10.1 Timeline de Ejecuci√≥n

```mermaid
gantt
    title Plan de Pruebas - Chatbot DCCO
    dateFormat  YYYY-MM-DD
    section Preparaci√≥n
    Setup Ambiente           :active, prep1, 2025-08-13, 1d
    Configuraci√≥n Tools      :prep2, after prep1, 1d
    section Pruebas Unitarias
    Implementar Tests        :unit1, after prep2, 2d
    Ejecutar y Ajustar       :unit2, after unit1, 1d
    section Integraci√≥n
    Pruebas API              :int1, after unit2, 1d
    Pruebas E2E              :int2, after int1, 1d
    section No Funcionales
    Rendimiento              :perf1, after int2, 1d
    Seguridad                :sec1, after perf1, 1d
    section Reporte
    Documentaci√≥n            :rep1, after sec1, 1d
```

### 10.2 Hitos Importantes

| Fecha | Hito | Criterio de Aceptaci√≥n |
|-------|------|------------------------|
| 13/08 | Setup Completo | Ambiente funcionando |
| 15/08 | Pruebas Unitarias | 80% cobertura lograda |
| 17/08 | Integraci√≥n Lista | APIs validadas |
| 19/08 | Testing Completo | Todas las pruebas ejecutadas |
| 20/08 | Reporte Final | Documento entregado |

---

## 11. Recursos y Responsabilidades

### 11.1 Equipo de Testing
- **QA Lead:** Coordinaci√≥n y estrategia
- **QA Engineer:** Ejecuci√≥n de pruebas
- **Developer:** Soporte t√©cnico y fixes
- **DevOps:** Configuraci√≥n de ambientes

### 11.2 Recursos Necesarios
- **Hardware:** Servidor de pruebas (4GB RAM, 2 CPU)
- **Software:** Herramientas de testing y licencias
- **Tiempo:** 9 d√≠as persona para ejecuci√≥n completa
- **Presupuesto:** Servicios cloud para testing

---

## 12. Riesgos y Mitigaciones

### 12.1 Riesgos Identificados

| Riesgo | Probabilidad | Impacto | Mitigaci√≥n |
|--------|-------------|---------|------------|
| APIs externas no disponibles | Media | Alto | Mocks y datos de prueba |
| Tiempo insuficiente | Alta | Medio | Priorizar pruebas cr√≠ticas |
| Recursos limitados | Media | Medio | Automatizaci√≥n m√°xima |
| Defectos cr√≠ticos tard√≠os | Baja | Alto | Testing continuo |

### 12.2 Plan de Contingencia
- **Backup de datos:** Snapshots diarios
- **Rollback plan:** Versi√≥n estable anterior
- **Comunicaci√≥n:** Canal directo con stakeholders
- **Escalaci√≥n:** Proceso definido para issues cr√≠ticos

---

## 13. Conclusiones y Pr√≥ximos Pasos

### 13.1 Valor del Plan
Este plan de pruebas integral garantiza:
- **Calidad robusta** del sistema de chatbot
- **Confianza** en el despliegue a producci√≥n
- **Documentaci√≥n completa** para auditor√≠as
- **Proceso repetible** para futuras versiones

### 13.2 Pr√≥ximos Pasos
1. **Aprobaci√≥n** del plan por stakeholders
2. **Setup** del ambiente de pruebas
3. **Implementaci√≥n** de casos de prueba
4. **Ejecuci√≥n** seg√∫n cronograma
5. **Entrega** de reporte final

---

## 14. Anexos

### 14.1 Referencias
- [Django Testing Documentation](https://docs.djangoproject.com/en/stable/topics/testing/)
- [Pytest Documentation](https://docs.pytest.org/)
- [OWASP Testing Guide](https://owasp.org/www-project-web-security-testing-guide/)

### 14.2 Plantillas
- Template de caso de prueba
- Formato de reporte de defecto
- Checklist de calidad

---

**Documento preparado para exposici√≥n de Aseguramiento de Calidad de Software**  
**Universidad ESPE - Departamento de Ciencias de la Computaci√≥n**
